{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<span>\n",
    "<img src=\"http://www.sobigdata.eu/sites/default/files/logo-SoBigData-DEFINITIVO.png\" width=\"180px\" align=\"right\"/>\n",
    "</span>\n",
    "<span>\n",
    "**Author:** Giulio Rossetti (giulio.rossetti@gmail.com)<br/>\n",
    "**Python version:**  3.6<br/>\n",
    "**Last update:** 22/01/2018\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# *Titanic Case Study* \n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this notebook, we will try to figure out what sorts of people were likely to survive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Dataset Description](#dataset) \n",
    "2. [Data Cleaning](#cleaning) \n",
    "    1. [Missing Values](#mv)\n",
    "    2. [Feature Engineering](#fe)\n",
    "    3. [Feature Reshaping](#fr)\n",
    "3. [Exploratory Analysis](#ea)\n",
    "    1. [Features Distributions](#fd)\n",
    "    2. [Dispersion and Outliers](#do)\n",
    "    3. [Correlations](#cc)\n",
    "4. [Regression](#pred)\n",
    "    1. [Logistic Regression](#logit)\n",
    "    2. [Evaluation](#eval)\n",
    "    3. [Conclusions](#conclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn as sk # data mining tools\n",
    "import matplotlib.pylab as plt # plotting\n",
    "import seaborn as sns # advanced plotting\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset'></a>\n",
    "## 1. Dataset description ([to top](#top))\n",
    "As first step we load the whole Titanic Dataset and make confidence with its features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"data/titanic.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each record is described by 12 variables:\n",
    "\n",
    "- The **Survived** variable is our outcome or dependent variable. It is a binary nominal datatype of 1 for survived and 0 for did not survive. All other variables are potential predictor or independent variables. It's important to note, more predictor variables do not make a better model, but the right variables.\n",
    "\n",
    "- The **PassengerID** and **Ticket** variables are assumed to be random unique identifiers, that have no impact on the outcome variable. Thus, they will be excluded from analysis.\n",
    "\n",
    "- The **Pclass** variable is an ordinal datatype for the ticket class, a proxy for socio-economic status (SES), representing 1 = upper class, 2 = middle class, and 3 = lower class.\n",
    "\n",
    "- The **Name** variable is a nominal datatype. It could be used in feature engineering to derive the gender from title, family size from surname, and SES from titles like doctor or master. Since these variables already exist, we'll make use of it to see if title, like master, makes a difference.\n",
    "\n",
    "- The **Sex** and **Embarked** variables are a nominal datatype. They will be converted to dummy variables for mathematical calculations.\n",
    "\n",
    "- The **Age** and **Fare** variable are continuous quantitative datatypes.\n",
    "\n",
    "- The **SibSp** represents number of related siblings/spouse aboard and **Parch** represents number of related parents/children aboard. Both are discrete quantitative datatypes. This can be used for feature engineering to create a family size and is alone variable.\n",
    "\n",
    "- The **Cabin** variable is a nominal datatype that can be used in feature engineering for approximate position on ship when the incident occurred and SES from deck levels. However, since there are many null values, it does not add value and thus is excluded from analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleaning'></a>\n",
    "## 2. Data Cleaning ([to top](#top))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage, we will clean our data by \n",
    " 1. handling missing information, \n",
    " 2. creating new features for analysis, and \n",
    " 3. converting fields to the correct format for calculations and presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mv'></a>\n",
    "### 2.A Missing Values ([to top](#top))\n",
    "Reviewing the data, there does not appear to be any aberrant or non-acceptable data inputs.\n",
    "\n",
    "Are there null values or missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our scenario is safe to *impute* missung values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age'].fillna(titanic['Age'].median(), inplace = True)\n",
    "titanic['Embarked'].fillna(titanic['Embarked'].mode()[0], inplace = True)\n",
    "titanic['Fare'].fillna(titanic['Fare'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, not all the columns in our dataframe are useful for our analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_column = ['PassengerId','Cabin', 'Ticket']\n",
    "titanic.drop(drop_column, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fe'></a>\n",
    "### 2.B Feature Engineering ([to top](#top))\n",
    "Feature engineering is when we use existing features to create new features to determine if they provide new signals to predict our outcome. \n",
    "\n",
    "In order to better explicitate information hidden in the original data we engenier some new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating discrete variables as combinations of existing ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['FamilySize'] = titanic ['SibSp'] + titanic['Parch'] + 1\n",
    "titanic['IsAlone'] = 1 # initialize to yes/1 is alone\n",
    "titanic['IsAlone'].loc[titanic['FamilySize'] > 1] = 0 # now update to no/0 if family size is greater than 1\n",
    "\n",
    "titanic[['FamilySize', 'IsAlone']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning continuos variable\n",
    "In order to better analyze continuos variable we can transform them into discrete ones by binning.\n",
    "\n",
    "Bins can be built either fixing frequency or bin size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['FareBin'] = pd.qcut(titanic['Fare'], 4) # qcut: frequency bins\n",
    "titanic['AgeBin'] = pd.cut(titanic['Age'].astype(int), 5) # cut: equal size value bins\n",
    "\n",
    "titanic[['Fare', 'FareBin', 'Age', 'AgeBin']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Categorical (String) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify title names (Mr. Miss. Mrs. etx)\n",
    "# Split title from name\n",
    "\n",
    "titanic['Title'] = titanic['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "\n",
    "titanic[['Name', 'Title']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup rare title names\n",
    "\n",
    "stat_min = 10 \n",
    "title_names = (titanic['Title'].value_counts() < stat_min) # create a true false series with title name as index\n",
    "titanic['Title'] = titanic['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "\n",
    "titanic['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fr'></a>\n",
    "### 2.C Feature Reshaping ([to top](#top))\n",
    "\n",
    "Last, but certainly not least, we'll deal with formatting. Our categorical data imported as objects, which makes it difficult for mathematical calculations. We will convert object datatypes to categorical dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert categotical variables to numerical ones using Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# encode labels with value between 0 and n_classes-1.\n",
    "label = LabelEncoder()\n",
    "\n",
    "titanic['Sex_Code'] = label.fit_transform(titanic['Sex'])\n",
    "titanic['Embarked_Code'] = label.fit_transform(titanic['Embarked'])\n",
    "titanic['Title_Code'] = label.fit_transform(titanic['Title'])\n",
    "titanic['AgeBin_Code'] = label.fit_transform(titanic['AgeBin'])\n",
    "titanic['FareBin_Code'] = label.fit_transform(titanic['FareBin'])\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ea'></a>\n",
    "## 3. Exploratory Analysis ([to top](#top))\n",
    "Now that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fd'></a>\n",
    "### 3.A Features Distributions ([to top](#top))\n",
    "\n",
    "In order to understand how the values of a continuos feature distribute we can use the kde (Kernel Density Estimate) plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = titanic['Age'].plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare = titanic['Fare'].plot.kde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional Feature Distribution\n",
    "\n",
    "We can build kde plots also by grouping values of a same feature w.r.t. a categorical variable.\n",
    "\n",
    "For instance we can check if there are differences on the Age/Sex distributions of Survived/Dead passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = titanic.groupby(['Survived']).Age.plot.kde()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = titanic.groupby(['Sex']).Age.plot.kde()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = titanic.groupby(['Survived']).Fare.plot.kde()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = titanic.groupby(['Sex']).Fare.plot.kde()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = titanic.groupby(['Sex', 'Survived']).Age.plot.kde()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram plot\n",
    "We can also use Histograms instead of kde to capture binned class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx = titanic.FamilySize.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Conditional, Stacked) histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_histogram(df, column):\n",
    "\n",
    "    booldf1 = pd.DataFrame(titanic[titanic['Survived']==0][column])\n",
    "    booldf1.columns = ['Dead']\n",
    "    booldf2 = pd.DataFrame(titanic[titanic['Survived']==1][column])\n",
    "    booldf2.columns = ['Survived']\n",
    "    row_concat = pd.concat([booldf1, booldf2], axis=1)\n",
    "\n",
    "    ax = row_concat.plot.hist(stacked=True, alpha=0.6)\n",
    "    ax.set_xlabel(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_histogram(titanic, 'Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_histogram(titanic, 'FareBin_Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_histogram(titanic, 'Embarked_Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_histogram(titanic, 'FamilySize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_histogram(titanic, 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_histogram(titanic, 'Sex_Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_histogram(titanic, 'FamilySize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar charts\n",
    "Conversely from histograms (used to plot quantitative data with ranges of the data grouped into bins or intervals), bar charts plot categorical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survived by sex\n",
    "\n",
    "sx = titanic.groupby(['Sex']).Survived.sum().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survived count\n",
    "\n",
    "sx = titanic.groupby(['Survived']).Survived.count().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alone passengers\n",
    "\n",
    "sx = titanic.groupby(['IsAlone']).IsAlone.count().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alone passangers grouped by sex\n",
    "\n",
    "sx = titanic.groupby(['IsAlone', 'Sex']).IsAlone.count().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do being alone affect the survival rate?\n",
    "\n",
    "sx = titanic.groupby(['IsAlone', 'Survived']).IsAlone.count().plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Conditional and Normalized) Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_bar_plot(df, columns, by):\n",
    "    t1 = pd.DataFrame(df[columns].groupby(by).sum())\n",
    "    t1.columns = ['Survived']\n",
    "    t2 = pd.DataFrame(titanic[columns].groupby(by).count())\n",
    "    t2.columns = ['Total']\n",
    "    row_concat = pd.concat([t1, t2], axis=1)\n",
    "    row_concat['Percentage'] = row_concat['Survived'] / row_concat['Total']\n",
    "    return row_concat['Percentage'].plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival rate per Class\n",
    "\n",
    "sp = conditional_bar_plot(titanic, ['Survived', 'Pclass'], ['Pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival rate per Embarked\n",
    "\n",
    "se = conditional_bar_plot(titanic, ['Survived', 'Embarked'], ['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival rate per Fare (binned)\n",
    "\n",
    "sf = conditional_bar_plot(titanic, ['Survived', 'FareBin'], ['FareBin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival rate per Age (binned)\n",
    "\n",
    "sa = conditional_bar_plot(titanic, ['Survived', 'AgeBin'], ['AgeBin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival rate per Family Size\n",
    "\n",
    "sf = conditional_bar_plot(titanic, ['Survived', 'FamilySize'], ['FamilySize'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='do'></a>\n",
    "### 3.B Dispersion and Outliers ([to top](#top))\n",
    "\n",
    "Box plot is a method for graphically depicting groups of numerical data through their quartiles. Box plots may also have lines extending vertically from the boxes (whiskers) indicating variability outside the upper and lower quartiles.\n",
    "\n",
    "Box plots are non-parametric: they display variation in samples of a statistical population without making any assumptions of the underlying statistical distribution. The spacings between the different parts of the box indicate the degree of dispersion (spread) and skewness in the data, and show outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_box = titanic.boxplot(['Fare'], showfliers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_box = titanic.boxplot(['Age'], showfliers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_box = titanic.boxplot(['FamilySize'], showfliers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_by_cs = titanic.boxplot(['Fare'], by=['Pclass', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_by_cs = titanic.boxplot(['Age'], by=['Pclass', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_by_cs = titanic.boxplot(['FamilySize'], by=['Pclass', 'Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cc'></a>\n",
    "### 3.C Correlations ([to top](#top))\n",
    "\n",
    "A correlation coefficient is a numerical measure of some type of correlation, meaning a statistical relationships between two variables.\n",
    "\n",
    "Several types of correlation coefficients exist, each with their own definition and own range of usability and characteristics. They have in common that they assume values in the range from −1 to +1, where +1 indicates the strongest possible agreement and −1 the strongest possible disagreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target label\n",
    "Target = ['Survived']\n",
    "\n",
    "titanic_1 = titanic[['Sex','Pclass', 'Embarked', 'Title', 'Age', 'Fare', 'FamilySize', 'IsAlone', 'Survived']]\n",
    "titanic_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discrete Variable Correlation by Survival \n",
    "\n",
    "for x in titanic_1:\n",
    "    if titanic_1[x].dtype != 'float64' and x!=Target[0]:\n",
    "        print('\\nSurvival Correlation by:', x)\n",
    "        cor = titanic_1[[x, Target[0]]].groupby(x).mean()\n",
    "        print(cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that are more likely to survive:\n",
    " - Female passengers\n",
    " - 1st class passengers\n",
    " - C embarked\n",
    " - Those who are not alone\n",
    " - Those who have a FamilySize in [2, 4] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix\n",
    "\n",
    "The correlation matrix computes the correlation coefficients of the columns of a matrix. That is, row i and column j of the correlation matrix is the correlation between column i and column j of the original matrix. Note that the diagonal elements of the correlation matrix will be 1 (since they are the correlation of a column with itself). The correlation matrix is also symmetric since the correlation of column i with column j is the same as the correlation of column j with column i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corr = titanic_1.corr()\n",
    "plt.subplots(figsize =(14, 12))\n",
    "hm = sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plots\n",
    "\n",
    "A scatter plot (also called a scatterplot, scatter graph, scatter chart, scattergram, or scatter diagram)[3] is a type of plot or mathematical diagram using Cartesian coordinates to display values for typically two variables for a set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = scatter_matrix(titanic_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = titanic.plot.scatter(x='Age', y='Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = titanic.plot.scatter(x='Age', y='FamilySize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pred'></a>\n",
    "## 4. Regression ([to top](#top))\n",
    "\n",
    "Regression is a data mining technique used to predict a range of numeric values (also called continuous values), given a particular dataset. Commonly, regression is used to predict a numeric or continuous value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='logit'></a>\n",
    "### 4.A Logistic Regression ([to top](#top))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Logistic Regression?\n",
    "\n",
    "Logistic regression is the appropriate regression analysis to conduct when the dependent variable is dichotomous (binary, as is 'Survived' in our case). \n",
    "\n",
    "Like all regression analyses, the logistic regression is a predictive analysis.  Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.\n",
    "\n",
    "At the center of the logistic regression analysis is the task estimating the log odds of an event.\n",
    "\n",
    "Mathematically, logistic regression estimates a multiple linear regression function defined as:\n",
    "\n",
    "$$logit(p) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots \\beta_n x_n $$\n",
    "\n",
    "First we drop the target variable, 'survived', from the training set -- we store the target variable in its own dataframe. We also make a copy of the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_regression = titanic[['Survived', 'Pclass', 'Age', 'Fare', 'FamilySize', 'IsAlone', 'Sex_Code']]\n",
    "\n",
    "data = titanic_regression.drop(\"Survived\",axis=1)\n",
    "target = titanic_regression[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heavy lifting for logistic regression is done behind the scene by scikit-learn, a Python library. We take advantage of this abstractness. \n",
    "\n",
    "For validation purposes we split our data into **training set** (75%) and **test set** (25%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_holdout, y_train, y_holdout = train_test_split(data, target, test_size=0.25,  train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can:\n",
    "1. **fit** the logistic regression model on the training set, and\n",
    "2. **predict** the target on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "\n",
    "preds = logreg.predict(x_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can inspect the obtained model to capture feature relevance by looking at coefficient ($\\beta$) weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(titanic_regression.columns.delete(0))\n",
    "coeff_df.columns = ['Features']\n",
    "coeff_df[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df.plot.barh(x='Features', y='Coefficient Estimate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eval'></a>\n",
    "### 4.B Evaluation ([to top](#top))\n",
    "\n",
    "In order to evaluate the quality of prediction there exist several measures: all of them built upon the concept of **Confusion Matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "In the field of machine learning a confusion matrix is a specific table layout that allows visualization of the performance of an algorithm. \n",
    "\n",
    "Each row of the matrix represents the instances in a predicted class while each column represents the instances in an actual class (or vice versa). \n",
    "\n",
    "Given a Target class (i.e. Survived):\n",
    "- **True Positive (TP)** represent those instances correctly predicted to be True (i.e. we predict that a passenger will survive and it survived)\n",
    "- **False Positive (FP)** represent those instances incorrectly predicted to be True (i.e. we predict that a passenger will survive and it did not)\n",
    "- **True Negative (TN)** represent those instances correctly predicted to be False (i.e. we predict that a passenger will not survive and it not survived)\n",
    "- **False Negative (FT)** represent those instances incorrectly predicted to be False (i.e. we predict that a passenger will not survive and, instead, it did survive)\n",
    "\n",
    "Upon such classes are built several indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(C,class_labels=['0','1']):\n",
    "    \"\"\"\n",
    "    C: ndarray, shape (2,2) as given by scikit-learn confusion_matrix function\n",
    "    class_labels: list of strings, default simply labels 0 and 1.\n",
    "\n",
    "    Draws confusion matrix with associated metrics.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    assert C.shape == (2,2), \"Confusion matrix should be from binary classification only.\"\n",
    "    \n",
    "    # true negative, false positive, etc...\n",
    "    tn = C[0,0]; fp = C[0,1]; fn = C[1,0]; tp = C[1,1];\n",
    "\n",
    "    NP = fn+tp # Num positive examples\n",
    "    NN = tn+fp # Num negative examples\n",
    "    N  = NP+NN\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax  = fig.add_subplot(111)\n",
    "    ax.imshow(C, interpolation='nearest', cmap=plt.cm.gray)\n",
    "\n",
    "    # Draw the grid boxes\n",
    "    ax.set_xlim(-0.5,2.5)\n",
    "    ax.set_ylim(2.5,-0.5)\n",
    "    ax.plot([-0.5,2.5],[0.5,0.5], '-k', lw=2)\n",
    "    ax.plot([-0.5,2.5],[1.5,1.5], '-k', lw=2)\n",
    "    ax.plot([0.5,0.5],[-0.5,2.5], '-k', lw=2)\n",
    "    ax.plot([1.5,1.5],[-0.5,2.5], '-k', lw=2)\n",
    "\n",
    "    # Set xlabels\n",
    "    ax.set_xlabel('Predicted Label', fontsize=16)\n",
    "    ax.set_xticks([0,1,2])\n",
    "    ax.set_xticklabels(class_labels + [''])\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.xaxis.tick_top()\n",
    "    \n",
    "    # These coordinate might require some tinkering. Ditto for y, below.\n",
    "    ax.xaxis.set_label_coords(0.34,1.06)\n",
    "\n",
    "    # Set ylabels\n",
    "    ax.set_ylabel('True Label', fontsize=16, rotation=90)\n",
    "    ax.set_yticklabels(class_labels + [''],rotation=90)\n",
    "    ax.set_yticks([0,1,2])\n",
    "    ax.yaxis.set_label_coords(-0.09,0.65)\n",
    "\n",
    "\n",
    "    # Fill in initial metrics: tp, tn, etc...\n",
    "    ax.text(0,0,\n",
    "            'True Negative: %d\\n(Num Neg: %d)'%(tn,NN),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(0,1,\n",
    "            'False Negative: %d'%fn,\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(1,0,\n",
    "            'False Positive: %d'%fp,\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "\n",
    "    ax.text(1,1,\n",
    "            'True Positive: %d\\n(Num Pos: %d)'%(tp,NP),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    # Fill in secondary metrics: accuracy, true pos rate, etc...\n",
    "    ax.text(2,0,\n",
    "            'False Positive Rate: %.2f'%(fp / (fp+tn+0.)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(2,1,\n",
    "            'Recall: %.2f'%(tp / (tp+fn+0.)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(2,2,\n",
    "            'Accuracy: %.2f'%((tp+tn+0.)/N),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(0,2,\n",
    "            'Negative Pre Val: %.2f'%(1-fn/(fn+tn+0.)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(1,2,\n",
    "            'Precision: %.2f'%(tp/(tp+fp+0.)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "c = confusion_matrix(y_holdout, logreg.predict(x_holdout))\n",
    "show_confusion_matrix(c, ['Died', 'Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the otehrs, two scores characterize the outcome of a predictive model: *precision* and *recall* \n",
    "\n",
    "**Precision:** how many of the instances I predict to be True are really True?\n",
    "$$precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "**Recall:** how many True instances I was able to correctly predict?\n",
    "$$recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "To summarize the overall accuracy of a model we can also use the **F1-score**: it describes the armonic mean of *precision* and *recall*.\n",
    "\n",
    "$$F1 = \\frac{2TP}{2TP+FP+FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_holdout, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve\n",
    "\n",
    "In statistics, a receiver operating characteristic curve, i.e. ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.\n",
    "\n",
    "The ROC curve is created by plotting the True Positive Rate (Precision) against the False Positive Rate at various threshold settings.\n",
    "\n",
    "The higher the curve w.r.t. the baseline the better the prediction. The area under the ROC curve (AUCROC) can also be used to summarize ROC plots and compare differend models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_holdout, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_holdout, preds)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "### 4.C Conclusions ([to top](#top))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What did we do?\n",
    "We used the survival titanic data to train a classifier (a logistic model) that predicts survival of a passenger given several features. To do so:\n",
    "\n",
    "- We split the training data-set by 0.75-0.25 into training and holdout examples. \n",
    "- We performed dimensionality reduction by examining individual features and assessing how much impact they may have on the target variable. \n",
    "- We evaluated the performance of our model by printing out a confusion matrix obtained from the holdout data-set. \n",
    "- We printed out the f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python36]",
   "language": "python",
   "name": "conda-env-Python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
